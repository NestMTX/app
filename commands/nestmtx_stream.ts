/**
 * This script starts an audio/video stream to the MediaMTX server
 * The script outputs 2 video streams:
 * - 1 encoded with the H.264 codec without b-frames
 * - 1 encoded with the H.264 codec with b-frames
 * and 2 audio streams:
 * - 1 encoded with the AAC codec
 * - 1 encoded with the Opus codec
 * It also is able to switch between 4 possible video sources:
 * - Source 1: an MJPEG stream which has no audio which emits a frame every 100ms used as stream to show while initializing other streams
 * - Source 2: an MJPEG stream which has no audio which emits a frame every 100ms used as stream to show when the desired path has no associated camera
 * - Source 3: an MJPEG stream which has no audio which emits a frame every 100ms used as stream to show when the camera associated with the desired path is disabled
 * - Source 4: Either
 *  * a remote RTSPS stream over UDP hosted on Google Nests' Cloud. Video is encoded with the H.264 codec and audio is encoded with the AAC codec
 *  * a stream of RTP packets over UDP which are generated by requesting a stream from Google's Nest camera over WebRTC. Video is encoded with the H.264 codec and audio is encoded with the Opus codec
 */
import { execa } from 'execa'
import { BaseCommand, args } from '@adonisjs/core/ace'
import { readFile } from 'node:fs/promises'
import { existsSync, unlinkSync, createReadStream } from 'node:fs'
import { DateTime } from 'luxon'
import { getRtspStreamCharacteristics } from '#utilities/rtsp'
import { getHostnameFromRtspUrl } from '#utilities/url'
import env from '#start/env'
import Camera from '#models/camera'
import string from '@adonisjs/core/helpers/string'

import type { CommandOptions } from '@adonisjs/core/types/ace'
import type { ExecaChildProcess } from 'execa'
import type { smartdevicemanagement_v1 } from 'googleapis'
import type { RtspStreamCharacteristics } from '#utilities/rtsp'

export default class NestmtxStream extends BaseCommand {
  static commandName = 'nestmtx:stream'
  static description = 'Start a stream to the MediaMTX server'

  static options: CommandOptions = {
    startApp: true,
  }

  @args.string({ description: 'The path to start the stream for' })
  declare path: string

  get cameraMissingFilePath() {
    return this.app.makePath('resources', 'mediamtx', 'no-such-camera.jpg')
  }

  get cameraDisabledFilePath() {
    return this.app.makePath('resources', 'mediamtx', 'camera-disabled.jpg')
  }

  get cameraConnectingFilePath() {
    return this.app.makePath('resources', 'mediamtx', 'connecting.jpg')
  }

  get #ffmpegArgs() {
    const outputRtspUrl = `rtsp://127.0.0.1:${env.get('MEDIA_MTX_RTSP_TCP_PORT', 8554)}/${this.path}`
    return [
      '-loglevel',
      'debug',
      '-hide_banner',

      // Read from stdin
      '-re',
      '-i',
      'pipe:0',

      // First video stream: H.264 without B-frames
      '-map',
      '0:v',
      '-c:v:0',
      'libx264',
      '-b:v:0',
      '500k',
      '-bf:v:0',
      '0',

      // Second video stream: H.264 with B-frames
      '-map',
      '0:v',
      '-c:v:1',
      'libx264',
      '-b:v:1',
      '500k',
      '-bf:v:1',
      '2',

      // First audio stream: AAC from FIFO
      '-map',
      '1:a',
      '-c:a:0',
      'aac',
      '-b:a:0',
      '128k',

      // Second audio stream: Opus from FIFO
      '-map',
      '1:a',
      '-c:a:1',
      'libopus',
      '-b:a:1',
      '128k',

      // Speed and Latency Optimizations
      '-preset',
      'ultrafast',
      '-tune',
      'zerolatency',
      '-maxrate',
      '2M',
      '-bufsize',
      '512k',
      '-threads',
      '1',
      '-fps_mode',
      'cfr',
      '-crf',
      '28',
      '-g',
      '10',
      '-slice-max-size',
      '1500',

      // Output to RTSP
      '-f',
      'rtsp',
      '-rtsp_transport',
      'udp',
      outputRtspUrl,
    ] as Array<string>
  }

  #muxer?: ExecaChildProcess
  #gstreamer?: ExecaChildProcess

  #cameraMissingJpg?: Buffer
  #cameraDisabledJpg?: Buffer
  #cameraConnectingJpg?: Buffer
  #audioFifoPath?: string
  #videoFifoPath?: string

  async run() {
    this.logger.info(`NestMTX Streamer for "${this.path}"`)
    this.#audioFifoPath = this.app.makePath(
      'resources',
      `${string.camelCase(this.path)}.audio.fifo`
    )
    this.#videoFifoPath = this.app.makePath(
      'resources',
      `${string.camelCase(this.path)}.video.fifo`
    )
    if (existsSync(this.#audioFifoPath)) {
      unlinkSync(this.#audioFifoPath)
    }
    if (existsSync(this.#videoFifoPath)) {
      unlinkSync(this.#videoFifoPath)
    }
    await execa('mkfifo', ['-m', '0777', this.#audioFifoPath])
    await execa('mkfifo', ['-m', '0777', this.#videoFifoPath])
    const ffmpegBinary = env.get('FFMPEG_BIN', 'ffmpeg')
    /**
     * Load the static images
     */
    const [cameraMissingJpg, cameraDisabledJpg, cameraConnectingJpg] = await Promise.all([
      readFile(this.cameraMissingFilePath),
      readFile(this.cameraDisabledFilePath),
      readFile(this.cameraConnectingFilePath),
    ])
    this.#cameraMissingJpg = cameraMissingJpg
    this.#cameraDisabledJpg = cameraDisabledJpg
    this.#cameraConnectingJpg = cameraConnectingJpg
    /**
     * Start the muxer process and the "connecting" stream
     */
    this.logger.info(`Starting ffmpeg stream to "${this.path}"`)
    this.#muxer = execa(ffmpegBinary, this.#ffmpegArgs, {
      cleanup: true,
      buffer: false,
      reject: false,
      stdin: 'pipe',
      stdout: 'inherit',
      stderr: 'inherit',
    })
    const audioFifoStream = createReadStream(this.#audioFifoPath)
    const videoFifoStream = createReadStream(this.#videoFifoPath)
    let audioFifoStreamConfirmed = false
    let videoFifoStreamConfirmed = false
    audioFifoStream.on('data', (chunk: Buffer) => {
      if (!audioFifoStreamConfirmed) {
        audioFifoStreamConfirmed = true
        this.logger.info('Audio FIFO stream confirmed')
      }
      this.#muxer!.stdin?.write(chunk)
    })
    videoFifoStream.on('data', (chunk: Buffer) => {
      if (!videoFifoStreamConfirmed) {
        videoFifoStreamConfirmed = true
        this.logger.info('Video FIFO stream confirmed')
      }
      this.#muxer!.stdin?.write(chunk)
    })
    // audioFifoStream.pipe(this.#muxer.stdin!)
    // videoFifoStream.pipe(this.#muxer.stdin!)
    this.#muxer.on('exit', (code, signal) => {
      this.logger.info(`FFmpeg Muxer exited with code ${code} and signal ${signal}`)
      process.exit(code ? code : 1)
    })
    this.#cameraConnectingStart()
    /**
     * Attempting to find the camera associated with the path
     */
    const camera = await Camera.findBy({ mtx_path: this.path })
    if (!camera) {
      this.logger.info('No camera found for path')
      this.#cameraMissingStart()
    } else if (
      !camera.isEnabled ||
      !camera.protocols ||
      (!camera.protocols.includes('WEB_RTC') && !camera.protocols.includes('RTSP'))
    ) {
      this.logger.info('Camera is disabled')
      this.#cameraDisabledStart()
    } else {
      await camera.load('credential')
      const service: smartdevicemanagement_v1.Smartdevicemanagement =
        await camera.credential.getSDMClient()
      try {
        if (camera.protocols.includes('WEB_RTC')) {
        } else if (camera.protocols.includes('RTSP')) {
          this.#rtspStart(service, camera)
        }
      } catch (err) {
        this.logger.error(err)
        process.exit(1)
      }
    }
  }

  /**
   * Camera Missing Functionality
   */
  #cameraMissingAbortController?: AbortController
  #cameraMissingStart() {
    if (!this.#muxer) {
      return
    }
    this.logger.info('Switching to camera missing stream')
    this.#cameraDisabledStop()
    this.#cameraConnectingStop()
    if (this.#cameraMissingAbortController) {
      this.#cameraMissingAbortController.abort()
    }
    this.#cameraMissingAbortController = new AbortController()
    this.#muxer!.stdin?.write(this.#cameraMissingJpg)
    const interval = setInterval(() => {
      this.#muxer!.stdin?.write(this.#cameraMissingJpg)
    }, 100)
    this.#cameraMissingAbortController.signal.onabort = () => {
      clearInterval(interval)
      this.#cameraMissingAbortController = undefined
    }
  }

  #cameraMissingStop() {
    if (this.#cameraMissingAbortController) {
      this.#cameraMissingAbortController.abort()
    }
  }

  /**
   * Camera Disabled Functionality
   */
  #cameraDisabledAbortController?: AbortController
  #cameraDisabledStart() {
    if (!this.#muxer) {
      return
    }
    this.logger.info('Switching to camera disabled stream')
    this.#cameraMissingStop()
    this.#cameraConnectingStop()
    if (this.#cameraDisabledAbortController) {
      this.#cameraDisabledAbortController.abort()
    }
    this.#cameraDisabledAbortController = new AbortController()
    this.#muxer!.stdin?.write(this.#cameraDisabledJpg)
    const interval = setInterval(() => {
      this.#muxer!.stdin?.write(this.#cameraDisabledJpg)
    }, 100)
    this.#cameraDisabledAbortController.signal.onabort = () => {
      clearInterval(interval)
      this.#cameraDisabledAbortController = undefined
    }
  }

  #cameraDisabledStop() {
    if (this.#cameraDisabledAbortController) {
      this.#cameraDisabledAbortController.abort()
    }
  }

  /**
   * Camera Connecting Functionality
   */
  #cameraConnectingAbortController?: AbortController
  #cameraConnectingStart() {
    if (!this.#muxer) {
      return
    }
    this.logger.info('Switching to camera connecting stream')
    this.#cameraMissingStop()
    this.#cameraDisabledStop()
    if (this.#cameraConnectingAbortController) {
      this.#cameraConnectingAbortController.abort()
    }
    this.#cameraConnectingAbortController = new AbortController()
    const interval = setInterval(() => {
      this.#muxer?.stdin?.write(this.#cameraConnectingJpg)
    }, 100)
    this.#cameraConnectingAbortController.signal.onabort = () => {
      clearInterval(interval)
      this.#cameraConnectingAbortController = undefined
    }
  }

  #cameraConnectingStop() {
    if (this.#cameraConnectingAbortController) {
      this.#cameraConnectingAbortController.abort()
    }
  }

  /**
   * RTSP Camera Stream Functionality
   */
  async #rtspStart(service: smartdevicemanagement_v1.Smartdevicemanagement, camera: Camera) {
    if (!this.#muxer) {
      return
    }
    const gstreamerBinary = env.get('GSTREAMER_BIN', 'gst-launch-1.0')
    const {
      data: { results },
    } = await service.enterprises.devices.executeCommand({
      name: camera.uid,
      requestBody: {
        command: 'sdm.devices.commands.CameraLiveStream.GenerateRtspStream',
      },
    })
    if (!results!.streamUrls || !results!.streamUrls.rtspUrl) {
      throw new Error('RTSP Stream URL not found')
    }
    if (!results!.streamExtensionToken) {
      throw new Error('No stream extension token found')
    }

    camera.streamExtensionToken = results!.streamExtensionToken
    camera.expiresAt = DateTime.utc().plus({ minutes: 5 })
    if (results!.expiresAt) {
      const expiresAt = DateTime.fromISO(results!.expiresAt)
      if (expiresAt.isValid) {
        camera.expiresAt = expiresAt
      }
    }
    await camera.save()
    const rtspSrc = results!.streamUrls.rtspUrl
    this.logger.info(`Getting RTSP stream characteristics for "${getHostnameFromRtspUrl(rtspSrc)}"`)
    const characteristics: RtspStreamCharacteristics = await getRtspStreamCharacteristics(rtspSrc)
    this.#cameraMissingStop()
    this.#cameraDisabledStop()
    this.#cameraConnectingStop()
    // Now we start the GStreamer process to feed the FFmpeg process (muxer)
    const gstreamerArgs = this.#getGStreamerArgs(characteristics)
    this.logger.info(`Starting GStreamer pipeline for RTSP stream`)

    this.#gstreamer = execa(gstreamerBinary, gstreamerArgs, {
      stdin: 'pipe',
      stdout: 'inherit',
      stderr: 'inherit',
      reject: false,
      shell: true,
    })
    this.#gstreamer.on('exit', async (code, signal) => {
      if (1 === code) {
        const res = await this.#gstreamer!
        this.logger.info(res.escapedCommand)
      } else {
        this.logger.info(`GStreamer exited with code ${code} and signal ${signal}`)
      }
      process.exit(code ? code : 1)
    })
  }

  #getGStreamerArgs(characteristics: RtspStreamCharacteristics) {
    const videoCaps = `video/x-h264,width=${characteristics.video.width},height=${characteristics.video.height},framerate=${characteristics.video.frameRate}/1`
    const audioCaps = `audio/mpeg,mpegversion=4,channels=${characteristics.audio.channels},rate=${characteristics.audio.sampleRate}`

    return [
      '-q', // Quiet mode
      '--gst-debug-level=2', // Log level set to WARNING
      'rtspsrc',
      `location=${characteristics.url}`,
      'timeout=10000000',
      'latency=0', // To reduce latency
      '!',
      'rtpjitterbuffer',
      '!',
      'rtph264depay', // For video stream
      '!',
      videoCaps,
      '!',
      'queue',
      '!',
      'h264parse',
      '!',
      'mpegtsmux',
      '!',
      `filesink location=${this.#videoFifoPath}`,

      'rtspsrc',
      `location=${characteristics.url}`,
      'timeout=10000000',
      'latency=0',
      '!',
      'application/x-rtp,media=audio',
      '!',
      'rtpmp4gdepay', // For audio stream
      '!',
      audioCaps,
      '!',
      'faad',
      '!',
      'audioconvert',
      '!',
      'fdkaacenc',
      '!',
      'mpegtsmux',
      '!',
      `filesink location=${this.#audioFifoPath}`,
    ]
  }
}
